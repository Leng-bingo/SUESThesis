# 《ImageNet Classiﬁcation with Deep Convolutional Neural Networks》

- `AlexNet`论文链接：https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf

---

### Abstract

![](https://leng-mypic.oss-cn-beijing.aliyuncs.com/mac-img/20220510163637.png)

- 前2句话介绍了自己做的工作，训练了一个很大很深的卷积神经网络在LSVRC-2010 contest取得了很好的结果。
- 第3句话介绍了网络的模型，有6000万个参数和65万个神经元，模型包含5个卷积层，以及最大池化层和3个全连接层。
- 第4句和第5句介绍了如何训练网络，使用了不饱和的神经元和GPU实现，为了减少全连接层的过拟合，使用了dropout技术。
- 最后一句， 介绍在ILSVRC-2012比赛取得了第一名，错误率比第二名低了10.9%，可以看到本文设计的网络模型效果很好。

---

### Introduction

<img src="https://leng-mypic.oss-cn-beijing.aliyuncs.com/mac-img/20220510162655.png"  />

`Introduction`部分，分为5段。前3段主要是研究内容背景知识介绍，第4段介绍了本文主要贡献。本文训练了一个很大的卷积神经网络在ILSVRC比赛上取得了最好的结果，同时本文在GPU实现了2D卷积操作。本文训练的网络包含一些`新的和不常见的特征来提高网络性能和减少训练时间`，这部分在论文第3节进行了介绍。第4节介绍了`新的技术来防止过拟合`。整个网络包含5个卷积层和3个全连接层，同时发现网络深度是很重要的，即使移除任意一层卷积层，都会导致性能下降。

---

### Dataset

![](https://leng-mypic.oss-cn-beijing.aliyuncs.com/mac-img/20220510162841.png)

`ImageNet Dataset`部分，分为3段。介绍了整个数据集大约有1500万张图片，共有22000类。ILSVRC比赛共有1000类，每一类大约有1000张图片。在2010的比赛中，可以得到测试集数据标签，但是在2012年的比赛中则没有测试集标签。

由于ImageNet数据集图片精度并不相同，因此我们每一张图片下采样到 256 × 256。当短边尺寸小于256时，我们先上采样到256，然后再从图片中截取 256 × 256的图片作为输入。我们没有对图片进行任何的预处理，整个网络是在每个像素的原始RGB值进行训练（也就是端到端训练，这也是深度学习的一大优势）。

---


### Architecture

![](https://leng-mypic.oss-cn-beijing.aliyuncs.com/mac-img/20220510163234.png)


首先介绍的是ReLU激活函数，函数形式为$f(x)=max(0,x)$，形式比较简单。

---

![](https://leng-mypic.oss-cn-beijing.aliyuncs.com/mac-img/20220510163854.png)

然后是网络结构介绍，输入是 224 × 224 × 3 224\times224\times3 224×224×3 的图片，然后是5个卷积层，接着是3个全连接层，最后一层是softmax层，输出为1000个类别标签的预测概率分布。使用了两个GPU进行训练（现在训练网络一般可以不同分割模型），将网络模型切成两半分别在两个GPU中进行训练。第2个、第4个和第5个卷积层的输入为同一GPU上之前一层卷积层的输出，而第3个卷积层的输入为两个GPU上的第2个卷积层输出。每个全连接层的输入都为前一层网络的全部输出。可以看到，随着网络深度的增加，卷积层中图像大小在减少，而深度在不断增加。

---

### Reducing Overfitting

- 使用数据增强，扣掉一个32x32的块，以增强数据的多样性。
- 利用PCA来修改图片的颜色。
- 再利用dropout，50%概率丢掉神经元，用于前两个全连接层。

---

### Learning

- SGD随机梯度下降来训练。
- 学习率为自动改变，每当误差率不变时，就除以10。
